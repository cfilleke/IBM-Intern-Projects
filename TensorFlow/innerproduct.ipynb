{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "innerproduct.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oL-G5XpVkk6w",
        "outputId": "849ebdf4-585b-46e2-c7f9-eded5b0ff114"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      arr1    arr2\n",
            "0   [1, 2]  [1, 1]\n",
            "1   [2, 2]  [1, 1]\n",
            "2   [2, 1]  [1, 1]\n",
            "3   [1, 1]  [2, 2]\n",
            "4   [2, 1]  [2, 1]\n",
            "..     ...     ...\n",
            "95  [2, 2]  [1, 2]\n",
            "96  [1, 2]  [2, 2]\n",
            "97  [2, 2]  [1, 1]\n",
            "98  [2, 1]  [1, 2]\n",
            "99  [2, 1]  [2, 1]\n",
            "\n",
            "[100 rows x 2 columns]\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='input_29'), name='input_29', description=\"created by layer 'input_29'\"), but it was called on an input with incompatible shape (None, 100, 2).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='input_30'), name='input_30', description=\"created by layer 'input_30'\"), but it was called on an input with incompatible shape (None, 100, 2).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='input_29'), name='input_29', description=\"created by layer 'input_29'\"), but it was called on an input with incompatible shape (None, 100, 2).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='input_30'), name='input_30', description=\"created by layer 'input_30'\"), but it was called on an input with incompatible shape (None, 100, 2).\n",
            "1/1 [==============================] - 0s 460ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2983 - accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.2983 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-cf1578490395>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m probability_model = tf.keras.Sequential([model, \n\u001b[0;32m---> 76\u001b[0;31m                                          tf.keras.layers.Softmax()])\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    596\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0mx_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m       \u001b[0;32massert\u001b[0m \u001b[0mx_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensor_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Could not compute output '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m       \u001b[0moutput_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: Exception encountered when calling layer \"model_11\" (type Functional).\n\nCould not compute output KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_31/Relu:0', description=\"created by layer 'dense_31'\")\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(None, 1), dtype=float32)\n  • training=None\n  • mask=None"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "# Create a neural net model to calculate the dot (inner product) \n",
        "# of any two vectors.\n",
        "\n",
        "# Calculate the vector dot (inner) product for any two vectors, \n",
        "# which are numpy int arrays.\n",
        "def vector_dot_scratch(a,b):\n",
        "\n",
        "  # The value is -1 if vectors have different shapes (lengths).\n",
        "  if(np.shape(a) != np.shape(b)):\n",
        "     c = -1\n",
        "  else:\n",
        "    c = 0\n",
        "    for i in range(np.array(a).size):\n",
        "      c += a[i-1]*b[i-1]\n",
        "  return c\n",
        "\n",
        "# Create two arrays a, b to store vectors of random length with random elements.\n",
        "# Create c a third array to store the corresponding inner products.  \n",
        "arr1 = []\n",
        "arr2 = []\n",
        "inner = []\n",
        "for i in range(100):\n",
        "  # the first part of a, b is the value that an element can take on, and\n",
        "  # the second part is the length of the array.\n",
        "  a = [random.randint(1,2) for x in range(2)]\n",
        "  arr1.append(a)\n",
        "  b = [random.randint(1,2) for x in range(2)]\n",
        "  arr2.append(b)\n",
        "  c = vector_dot_scratch(a,b)\n",
        "  inner.append(c)\n",
        "\n",
        "# Create a data frame for the vectors and their inner products.\n",
        "df = pd.DataFrame()\n",
        "df['arr1'] = arr1\n",
        "df['arr2'] = arr2\n",
        "target = tf.zeros([1, 1])\n",
        "\n",
        "print(df)\n",
        "\n",
        "# Creation of ragged tensors (arrays of different lengths) \n",
        "# to contain the features and target of the dataframe.\n",
        "feature1 = tf.constant(([df['arr1']]))\n",
        "feature2 = tf.constant(([df['arr2']]))\n",
        "\n",
        "\n",
        "#print(feature1.shape)\n",
        "#print(target.shape)\n",
        "\n",
        "# MODEL SECTION\n",
        "# Adapted from https://www.tensorflow.org/tutorials/keras/classification\n",
        "\n",
        "# Creation of neural net model.\n",
        "# From https://stackoverflow.com/questions/55233377/keras-sequential-model-with-multiple-inputs\n",
        "input1 = keras.layers.Input(shape=(1, ))\n",
        "input2 = keras.layers.Input(shape=(1,))\n",
        "merged = keras.layers.Concatenate(axis=1)([input1, input2])\n",
        "dense1 = keras.layers.Dense(2, input_dim=2, activation=keras.activations.sigmoid, use_bias=True)(merged)\n",
        "output = keras.layers.Dense(1, activation=keras.activations.relu, use_bias=True)(dense1)\n",
        "model = keras.models.Model([input1, input2], output)\n",
        "\n",
        "# Compilation of model.\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Model fitting.\n",
        "model.fit([feature1, feature2], target, epochs=100)\n",
        "\n",
        "probability_model = tf.keras.Sequential([model, \n",
        "                                         tf.keras.layers.Softmax()])\n",
        "\n",
        "\n"
      ]
    }
  ]
}