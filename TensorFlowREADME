# Accumulating background information

1.	**TensorFlow YouTube Tutorials:** 
a.	TensorFlow In 10 Minutes | TensorFlow Tutorial For Beginners | Deep Learning & TensorFlow | Edureka: https://www.youtube.com/watch?v=tXVNS-V39A0  
(Topics covered: What is TensorFlow? Companies using TensorFlow. Features of TensorFlow. What are Tensors? What are Neural Networks? TensorFlow Open Source Community) 
b.	Tensorflow Tutorial for Python in 10 Minutes https://www.youtube.com/watch?v=6_2hzRopPbQ 
PLUS accompanying Jupyter notebook: https://github.com/nicknochnack/Tensorflow-in-10-Minutes/blob/main/Tensorflow%20in%2010.ipynb
c.	TensorFlow 2.0 Complete Course - Python Neural Networks for Beginners Tutorial https://www.youtube.com/watch?v=tPYj3fFJGjk 
Comes complete with Jupyter Notebooks for modules 2 – 7. Topics Covered: 
(00:03:25) Module 1: Machine Learning Fundamentals 
(00:30:08) Module 2: Introduction to TensorFlow
(01:00:00) Module 3: Core Learning Algorithms
(02:45:39) Module 4: Neural Networks with TensorFlow
(03:43:10) Module 5: Deep Computer Vision - Convolutional Neural Networks
(04:40:44) Module 6: Natural Language Processing with RNNs
(06:08:00) Module 7: Reinforcement Learning with Q-Learning
(06:48:24) Module 8: Conclusion and Next Steps
d.	Training Performance: A user’s guide to converge faster (TensorFlow Dev Summit 2018) 
https://www.youtube.com/watch?v=SxOsJPaxHME “how to optimize training speed of your models on modern accelerators (GPUs and TPUs). 
Learn about how to interpret profiling tools and techniques to parallelize and overlap work to converge faster”

2.	**TensorFlow Site:** https://www.tensorflow.org/ Looking at three areas: Neural Nets, Recommender Systems, and Generative Adversarial Networks (GANs).

3.	**Neural Net resources:** 
a.	https://github.com/IBM/zDNN: “IBM Z Deep Neural Network Library (zDNN) provides an interface for applications making use of 
Neural Network Processing Assist Facility (NNPA).” 
b.	https://onnx.ai/: “ONNX is an open format built to represent machine learning models. ONNX defines a common set of operators - 
the building blocks of machine learning and deep learning models - and a common file format to enable AI developers to use models with 
a variety of frameworks, tools, runtimes, and compilers.”

4.	**Generative Adversarial Networks (GANs):** https://developers.google.com/machine-learning/gan/ The generator creates false data, and the discriminator 
tries to determine if the data it received is the false data from the generator or real data. 
Discriminator loss occurs if the discriminator cannot identify the false data; 
Generator loss occurs if the generator cannot “fool” the discriminator, so that its generated false data is not accepted as if it were real data. 
Below: a link to a Colab Jupyter notebook to “to define, train, and evaluate” GANs
https://colab.research.google.com/github/tensorflow/gan/blob/master/tensorflow_gan/examples/colab_notebooks/tfgan_tutorial.ipynb?utm_source=ss-gan&utm_campaign=colab-external&utm_medium=referral&utm_content=tfgan-intro

5.	**Article on Optimization of Training Time:** “Tricks to improve TensorFlow training time with tf.data pipeline optimizations, 
mixed precision training and multi-GPU strategies” 
https://www.kdnuggets.com/2020/03/tensorflow-optimizing-training-time-performance.html  
The strategy highlighted here is MirroredStrategy. “It instantiates your model on each GPU. 
At each step, different batches are sent to the GPUs which run the backward pass. 
Then, gradients are aggregated to perform weights update, and the updated values are propagated to each model instantiated.”

6.	**Mathematics:**
a.	Tensors: https://www.youtube.com/watch?v=f5liqUk0ZTw 
The combination of tensor components and basis vectors is the same for all observers (in every reference frame).
b.	Kernel methods: https://en.wikipedia.org/wiki/Kernel_method

7.	**IBM and TensorFlow:**
a.	TensorFlow, TensorFlow Serving, and TensorFlow Transform for Linux on IBM Z and LinuxONE 
https://community.ibm.com/community/user/ibmz-and-linuxone/blogs/javier-perez1/2020/12/16/tensorflow-tensorflow-serving-and-tensorflow-trans 
i.	“TensorFlow Serving functionality installed via PIP package manager or Docker image facilitates deploying models 
to start serving prediction requests in a consistent architecture and with APIs.” https://github.com/linux-on-ibm-z/docs/wiki/Building-TensorFlow-Serving
ii.	“TensorFlow Transform (tf.Transform) is a Python library for TensorFlow that allows the preprocessing of input data. 
Users can define preprocessing pipelines and export them to run as part of a TensorFlow graph. 
Examples of data transformation include: normalizing values by using the mean and standard deviation functions, converting strings to integers, 
or floating types to integers, among others. With TensorFlow Transform serving-time transformations are the same as those performed at training-time.” 
https://github.com/linux-on-ibm-z/docs/wiki/Building-TensorFlow-Transform
